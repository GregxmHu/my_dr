import os
import time
import argparse
#import random
from sklearn import datasets

parser = argparse.ArgumentParser()
parser.add_argument("--model", default="sgpt-125M", type=str)
parser.add_argument("--pooling", default="weightedmean", type=str)
parser.add_argument("--datasets", default="sgpt-125M", type=str)
parser.add_argument("--margin", default=0.1, type=int)
args = parser.parse_args()

dir="/data/home/scv0540/run/my_dr/checkpoints/{}_{}-pooling_{}".format(args.model,args.pooling,args.datasets)
map_file="{}/checkpoint_path.tsv".format(dir)
qrels_path="/data/home/scv0540/run/my_dr/datasets/{}/qrels-irrels.train.tsv".format(args.dataset)
qrels_path_list_file="/data/home/scv0540/run/my_dr/datasets/{}/qrels_path.tsv".format(args.dataset)
score_path="/data/home/scv0540/run/my_dr/scores/{}_{}-pooling_{}_test.txt".format(args.model,args.pooling,args.datasets)  
rs_list=[]
times=1
while True:
    with open(map_file,'r') as f:
        not_find=True
        for item in f:
            round_num,stage_num,path=item.strip('\n').split('\t')
            round_num,stage_num=int(round_num),int(stage_num)
            if (round_num,stage_num) not in rs_list:
                not_find=False
                print("******check-{} find new checkpoint in {}******\n".format(times,path))
                os.system("srun --job-name=inference_{}_{}-pooling_{}_round{}-stage{} --nodes=1 --gpus=8 --mem=300G --exclusive bash inference.sh {} {} {} {} {}".format(args.model,args.pooling,args.datasets,round_num,stage_num,args.model,args.pooling,args.datasets,round_num,stage_num) )
                rs_list.append((round_num,stage_num))
                # generate new qrels_file
                next_stage_qrels_path="/data/home/scv0540/run/my_dr/datasets/{}/round{}-stage{}_qrels-irrels.train.tsv".format(args.datasets,round_num,stage_num)
                #read scores generated by up inferenced
                scores={}
                with open(score_path,'r') as f:
                    for item in f:
                        item=item.strip('\n').split('\t')
                        qid,did,score=item[1],item[2],eval(item[4])
                        if qid not in scores:
                            scores[qid]={}
                        scores[qid][did]=score
                #according to new scores to generate new qrels
                dataset=[]
                with open (qrels_path,'r') as f:
                    for item in f:
                        qid,pos_ids_list_str,neg_ids_list_str=item.strip('\n').split('\t')
                        pos_ids_list=eval(pos_ids_list_str)
                        neg_ids_list=eval(neg_ids_list_str)
                        pos_min_score=min([scores[qid][did] for did in pos_ids_list])
                        neg_threshold_score=pos_min_score-args.margin
                        neg_ids_list=[neg_id for neg_id in neg_ids_list if scores[qid][neg_id]<neg_threshold_score][:5]
                        dataset.append((qid,pos_ids_list,neg_ids_list))
                with open(next_stage_qrels_path,'w') as f:
                    for item in dataset:
                        qid=item[0]
                        pos_ids=str(item[1])
                        neg_ids=str(item[2])
                        f.write(qid+'\t'+pos_ids+'\t'+neg_ids+'\n')
                print("generate new qrels_path at {}".format(next_stage_qrels_path))
                with open(qrels_path_list_file,'a') as f:
                    f.write(str(round_num)+'\t'+str(stage_num)+'\t'+next_stage_qrels_path+'\n')


        if not_find:
            print("******the {}'s check don't find new checkpoint******\n".format(times))
        time.sleep(600)
        times+=1
