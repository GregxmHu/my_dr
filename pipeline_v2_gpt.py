import os
import time
import argparse
import random
from sklearn import datasets
from tqdm import tqdm
from tqdm import trange
parser = argparse.ArgumentParser()
parser.add_argument("--model", default="sgpt-125M", type=str)
parser.add_argument("--pooling", default="weightedmean", type=str)
parser.add_argument("--datasets", default="sgpt-125M", type=str)
parser.add_argument("--total_round", default="1", type=int)
args = parser.parse_args()
### prepare ###
os.system("python prepare_v2.py --model {} --pooling {} --datasets {}".format(args.model,args.pooling,args.datasets))
### train + inference + generate new qrels + ...
qrels_dir="/data/home/scv0540/run/my_dr/datasets/{}/{}_{}-pooling_{}".format(args.datasets,args.model,args.pooling,args.datasets)
qrels_path_list_file="{}/qrels_path.tsv".format(qrels_dir)
score_path="/data/home/scv0540/run/my_dr/scores/{}_{}-pooling_{}_train.tsv".format(args.model,args.pooling,args.datasets)  
#qrels_path_list=[]
origin_qrels_path="/data/home/scv0540/run/my_dr/datasets/{}/qrels-irrels.train.tsv".format(args.datasets)
checkpoint_dir="/data/home/scv0540/run/my_dr/checkpoints/{}_{}-pooling_{}".format(args.model,args.pooling,args.datasets)
checkpoint_path_list_file="{}/checkpoint_path.tsv".format(checkpoint_dir)
#checkpoint_path_list=[]
for round_idx in range(args.total_round):
    for stage_idx in range(2):
        # train and save checkpoint
        os.system("srun --job-name=train_{}_{}-pooling_{}_round{}-stage{} --nodes=1 --gpus=8 --mem=300G --exclusive bash train_gpt125M_v2.sh {} {} {} {} {}".format(args.model,args.pooling,args.datasets,round_idx,stage_idx,args.model,args.pooling,args.datasets,round_idx,stage_idx) )
        # inference and generate new qrels according to scores 
        os.system("srun --job-name=inference_{}_{}-pooling_{}_round{}-stage{} --nodes=1 --gpus=8 --mem=300G --exclusive bash inference_v2.sh {} {} {} {} {}".format(args.model,args.pooling,args.datasets,round_idx,stage_idx,args.model,args.pooling,args.datasets,round_idx,stage_idx)  )
        next_stage_qrels_path="{}/round{}-stage{}_qrels-irrels.train.tsv".format(qrels_dir,round_idx,stage_idx)
        print("read scores generated by up inferenced")
        scores={}
        with open(score_path,'r') as f:
            for item in tqdm(f,disable=False):
                item=item.strip('\n').split('\t')
                qid,did,score=item[1],item[2],eval(item[4])
                if qid not in scores:
                    scores[qid]={}
                    scores[qid]['length']=0
                    scores[qid]['not_need']=False
                if scores[qid]['not_need']:
                    continue
                scores[qid][did]=score
                scores[qid]['length']+=1
                if scores[qid]['length']==100:
                    scores[qid]['not_need']=True
        print("according to new scores to generate new qrels")
        dataset=[]
        with open (origin_qrels_path,'r') as f:
            for item in tqdm(f,disable=False):
                qid,pos_ids_list_str,neg_ids_list_str=item.strip('\n').split('\t')
                pos_ids_list=eval(pos_ids_list_str)
                #neg_ids_list=eval(neg_ids_list_str)
                random.seed(13)
                neg_ids_list=random.sample([neg_id for neg_id in scores[qid] if neg_id not in pos_ids_list],5)
                dataset.append((qid,pos_ids_list,neg_ids_list))
        with open(next_stage_qrels_path,'w') as f:
            for item in tqdm(dataset,disable=False):
                qid=item[0]
                pos_ids=str(item[1])
                neg_ids=str(item[2])
                f.write(qid+'\t'+pos_ids+'\t'+neg_ids+'\n')
        print("generate new qrels_path at {}".format(next_stage_qrels_path))


